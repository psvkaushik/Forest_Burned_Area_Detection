{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8gSzigHPqRrE"
      },
      "outputs": [],
      "source": [
        "# !pip install datasets\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from datasets import load_dataset\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to store and read data from google drive\n",
        "from google.colab import drive\n",
        "from datasets import load_from_disk\n",
        "import shutil\n",
        "import os"
      ],
      "metadata": {
        "id": "k6N-9ivmBoTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "jc4Gvq5krFqh"
      },
      "outputs": [],
      "source": [
        "# dataset = load_dataset(\"DarthReca/california_burned_areas\", name=\"pre-post-fire\", trust_remote_code=True)\n",
        "dataset = load_dataset(\"DarthReca/california_burned_areas\", name=\"post-fire\", trust_remote_code=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLDIdS7Ek1DQ"
      },
      "outputs": [],
      "source": [
        "X_0 = dataset['0']['post_fire']\n",
        "print('done')\n",
        "X_1 = dataset['1']['post_fire']\n",
        "print('done')\n",
        "X_2 = dataset['2']['post_fire']\n",
        "print('done')\n",
        "X_3 = dataset['3']['post_fire']\n",
        "print('done')\n",
        "X_4 = dataset['4']['post_fire']\n",
        "print('done')\n",
        "X_c = dataset['chabud']['post_fire']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vkdnpI_GrXFY"
      },
      "outputs": [],
      "source": [
        "m_0 = dataset['0']['mask']\n",
        "print('done')\n",
        "m_1 = dataset['1']['mask']\n",
        "print('done')\n",
        "m_2 = dataset['2']['mask']\n",
        "print('done')\n",
        "m_3 = dataset['3']['mask']\n",
        "print('done')\n",
        "m_4 = dataset['4']['mask']\n",
        "print('done')\n",
        "m_c = dataset['chabud']['mask']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YbI3s1etrZyX"
      },
      "outputs": [],
      "source": [
        "# Add factor before split the data\n",
        "\n",
        "epsilon = 1e-10\n",
        "\n",
        "# Functions to calculate the indices with added epsilon\n",
        "def ndvi(b4, b8):\n",
        "    return (b8 - b4) / (b8 + b4 + epsilon)\n",
        "\n",
        "def abai(b3, b11, b12):\n",
        "    return (3 * b12 - 2 * b11 - 3 * b3) / (3 * b12 + 2 * b11 + 3 * b3 + epsilon)\n",
        "\n",
        "def nbr(b2, b3, b8a, b12):\n",
        "    return (b12 - b8a - b3 - b2) / (b12 + b8a + b3 + b2 + epsilon)\n",
        "\n",
        "def add_indices(image):\n",
        "    # Convert to a NumPy array if it's not already\n",
        "    image = np.array(image)\n",
        "\n",
        "    # Extract the required bands\n",
        "    b2, b3, b4, b8, b8a, b11, b12 = image[..., 1], image[..., 2], image[..., 3], image[..., 7], image[..., 8], image[..., 10], image[..., 11]\n",
        "    ndvi_band = ndvi(b4, b8)\n",
        "    abai_band = abai(b3, b11, b12)\n",
        "    nbr_band = nbr(b2, b3, b8a, b12)\n",
        "\n",
        "    # Stack indices as additional bands\n",
        "    return np.dstack((image, ndvi_band, abai_band, nbr_band))\n",
        "\n",
        "# Concatenate all images and masks\n",
        "all_images = [X_0, X_1, X_2, X_3, X_4, X_c]\n",
        "all_masks = [m_0, m_1, m_2, m_3, m_4, m_c]\n",
        "\n",
        "# Add indices to each image\n",
        "processed_images = []\n",
        "for subset in all_images:\n",
        "    for img in subset:\n",
        "        processed_images.append(add_indices(img))\n",
        "\n",
        "# Concatenate masks into a single list\n",
        "processed_masks = [mask for subset in all_masks for mask in subset]\n",
        "\n",
        "# Split into train and test sets\n",
        "train_X, test_X, train_Y, test_Y = train_test_split(processed_images, processed_masks, test_size=0.3)\n",
        "\n",
        "# Check the final shape of train_X\n",
        "#print(np.array(train_X).shape)  # Should be (421, 512, 512, 15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jfVEsKqv2EMT"
      },
      "outputs": [],
      "source": [
        "class AttentionBlock(nn.Module):\n",
        "    def __init__(self, in_channels, gating_channels, inter_channels):\n",
        "        super(AttentionBlock, self).__init__()\n",
        "\n",
        "        # 1x1 convolution for gating signal\n",
        "        self.phi_g = nn.Conv2d(gating_channels, inter_channels, kernel_size=1, padding='same')\n",
        "\n",
        "        # 1x1 convolution for input signal\n",
        "        self.theta_x = nn.Conv2d(in_channels, inter_channels, kernel_size=3, stride=1, padding='same')\n",
        "\n",
        "        # Combine gating and input signal\n",
        "        self.psi = nn.Conv2d(inter_channels, 1, kernel_size=1, padding='same')\n",
        "\n",
        "        # Normalization\n",
        "        self.bn = nn.BatchNorm2d(in_channels)\n",
        "\n",
        "    def forward(self, x, g):\n",
        "        # Get shapes\n",
        "        shape_x = x.shape\n",
        "        shape_g = g.shape\n",
        "\n",
        "        # Convolve the gating signal and the input signal\n",
        "        phi_g = self.phi_g(g)\n",
        "        theta_x = self.theta_x(x)\n",
        "\n",
        "        # Add the convolved features and apply ReLU\n",
        "        add_xg = F.relu(phi_g + theta_x)\n",
        "\n",
        "        # Sigmoid activation on the summed features\n",
        "        psi = torch.sigmoid(self.psi(add_xg))\n",
        "\n",
        "        # Upsample psi to the size of x\n",
        "        upsample_sigmoid_xg = F.interpolate(psi, size=(shape_x[2], shape_x[3]), mode='bilinear', align_corners=True)\n",
        "\n",
        "        # Multiply upsampled attention map with x (element-wise attention)\n",
        "        attn_coefficients = upsample_sigmoid_xg * x\n",
        "\n",
        "        # Consolidate to original x channels with a 1x1 convolution\n",
        "        output = self.bn(attn_coefficients)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLsx5wbzkTfa"
      },
      "outputs": [],
      "source": [
        "class UNetWithAttention(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(UNetWithAttention, self).__init__()\n",
        "\n",
        "        # Define encoder blocks (as in your original UNet)\n",
        "        self.orange = nn.Conv2d(in_channels=12, out_channels=64, kernel_size=7, padding='same')\n",
        "        self.red1 = nn.MaxPool2d(2)\n",
        "        self.blue1 = nn.Sequential(nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding='same'),\n",
        "                                   nn.BatchNorm2d(64),\n",
        "                                   nn.ReLU(inplace=True),\n",
        "                                   nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding='same'))\n",
        "        self.red2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=2, padding=1)\n",
        "        self.blue2 = nn.Sequential(nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding='same'),\n",
        "                                   nn.BatchNorm2d(128),\n",
        "                                   nn.ReLU(inplace=True),\n",
        "                                   nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding='same'))\n",
        "        self.red3 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=2, padding=1)\n",
        "        self.blue3 = nn.Sequential(nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding='same'),\n",
        "                                   nn.BatchNorm2d(256),\n",
        "                                   nn.ReLU(inplace=True),\n",
        "                                   nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding='same'))\n",
        "        self.red4 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=2, padding=1)\n",
        "        self.blue4 = nn.Sequential(nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding='same'),\n",
        "                                   nn.BatchNorm2d(512),\n",
        "                                   nn.ReLU(inplace=True),\n",
        "                                   nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding='same'))\n",
        "\n",
        "        # Define attention blocks for each skip connection\n",
        "        self.att1 = AttentionBlock(in_channels=256, gating_channels=512, inter_channels=128)\n",
        "        self.att2 = AttentionBlock(in_channels=128, gating_channels=256, inter_channels=64)\n",
        "        self.att3 = AttentionBlock(in_channels=64, gating_channels=128, inter_channels=32)\n",
        "        self.att4 = AttentionBlock(in_channels=64, gating_channels=64, inter_channels=32)\n",
        "\n",
        "        # Define decoder blocks (upsampling)\n",
        "        self.green1 = nn.ConvTranspose2d(in_channels=512, out_channels=512, kernel_size=2, stride=2)\n",
        "        self.upblue1 = nn.Sequential(nn.Conv2d(in_channels=768, out_channels=256, kernel_size=3, padding='same'),\n",
        "                                     nn.BatchNorm2d(256),\n",
        "                                     nn.ReLU(inplace=True),\n",
        "                                     nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding='same'))\n",
        "        self.green2 = nn.ConvTranspose2d(in_channels=256, out_channels=256, kernel_size=2, stride=2)\n",
        "        self.upblue2 = nn.Sequential(nn.Conv2d(in_channels=384, out_channels=128, kernel_size=3, padding='same'),\n",
        "                                     nn.BatchNorm2d(128),\n",
        "                                     nn.ReLU(inplace=True),\n",
        "                                     nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding='same'))\n",
        "        self.green3 = nn.ConvTranspose2d(in_channels=128, out_channels=128, kernel_size=2, stride=2)\n",
        "        self.upblue3 = nn.Sequential(nn.Conv2d(in_channels=192, out_channels=64, kernel_size=3, padding='same'),\n",
        "                                     nn.BatchNorm2d(64),\n",
        "                                     nn.ReLU(inplace=True),\n",
        "                                     nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding='same'))\n",
        "        self.green4 = nn.ConvTranspose2d(in_channels=64, out_channels=64, kernel_size=2, stride=2)\n",
        "        self.upblue4 = nn.Sequential(nn.Conv2d(in_channels=128, out_channels=32, kernel_size=3, padding='same'),\n",
        "                                     nn.BatchNorm2d(32),\n",
        "                                     nn.ReLU(inplace=True),\n",
        "                                     nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding='same'))\n",
        "\n",
        "        self.final_conv = nn.Conv2d(32, 1, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoder path\n",
        "        orange_op = self.orange(x)\n",
        "        red1_op = self.red1(orange_op)\n",
        "        blue1_op = self.blue1(red1_op) + red1_op\n",
        "        red2_op = self.red2(blue1_op)\n",
        "        blue2_op = self.blue2(red2_op) + red2_op\n",
        "        red3_op = self.red3(blue2_op)\n",
        "        blue3_op = self.blue3(red3_op) + red3_op\n",
        "        red4_op = self.red4(blue3_op)\n",
        "        blue4_op = self.blue4(red4_op) + red4_op\n",
        "\n",
        "        # Decoder path with attention\n",
        "        g1 = self.green1(blue4_op)\n",
        "        att1 = self.att1(blue3_op, g1)\n",
        "        up1_op = self.upblue1(torch.cat([g1, att1], dim=1))\n",
        "\n",
        "        g2 = self.green2(up1_op)\n",
        "        att2 = self.att2(blue2_op, g2)\n",
        "        up2_op = self.upblue2(torch.cat([g2, att2], dim=1))\n",
        "\n",
        "        g3 = self.green3(up2_op)\n",
        "        att3 = self.att3(blue1_op, g3)\n",
        "        up3_op = self.upblue3(torch.cat([g3, att3], dim=1))\n",
        "\n",
        "        g4 = self.green4(up3_op)\n",
        "        att4 = self.att4(orange_op, g4)\n",
        "        up4_op = self.upblue4(torch.cat([g4, att4], dim=1))\n",
        "\n",
        "        # Final output\n",
        "        return torch.sigmoid(self.final_conv(up4_op))\n",
        "\n",
        "\n",
        "model = UNetWithAttention()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UXKSTQ6ckcUx"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "class ImageData(Dataset):\n",
        "    def __init__(self, images, masks):\n",
        "        self.images = images\n",
        "        self.masks = masks\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        mask = self.masks[idx]\n",
        "        tensor_image = torch.tensor(image[:, :, [1, 2, 3, 4, 5, 6, 8, 10, 11, 12, 13,14]]).float().permute(2, 0, 1) #-> make changes to what channels you want to include\n",
        "        tensor_mask = torch.tensor(mask).float().permute(2, 0, 1)\n",
        "        return tensor_image, tensor_mask\n",
        "\n",
        "train_dataset = ImageData(images=train_X, masks=train_Y)\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "\n",
        "test_dataset = ImageData(images=test_X, masks=test_Y)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1YZYupokeZE"
      },
      "outputs": [],
      "source": [
        "def precision_score_(groundtruth_mask, pred_mask):\n",
        "    intersect = np.sum(pred_mask*groundtruth_mask)\n",
        "    total_pixel_pred = np.sum(pred_mask)\n",
        "    precision = np.mean(intersect/total_pixel_pred)\n",
        "    return round(precision, 3)\n",
        "\n",
        "def recall_score_(groundtruth_mask, pred_mask):\n",
        "    intersect = np.sum(pred_mask*groundtruth_mask)\n",
        "    total_pixel_truth = np.sum(groundtruth_mask)\n",
        "    recall = np.mean(intersect/total_pixel_truth)\n",
        "    return round(recall, 3)\n",
        "\n",
        "def dice_loss(groundtruth_mask, pred_mask):\n",
        "    intersect = torch.sum(pred_mask * groundtruth_mask)\n",
        "    total_sum = torch.sum(pred_mask) + torch.sum(groundtruth_mask)\n",
        "    dice = 1 - (2 * intersect / (total_sum + 1e-6))  # Avoid division by zero\n",
        "    return dice\n",
        "\n",
        "def iou_(groundtruth_mask, pred_mask):\n",
        "    intersect = np.sum(pred_mask*groundtruth_mask)\n",
        "    union = np.sum(pred_mask) + np.sum(groundtruth_mask) - intersect\n",
        "    return round(np.mean(intersect/union), 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6apiy0GklW8"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Define loss and optimizer\n",
        "criterion = nn.BCEWithLogitsLoss()  # Use BCEWithLogitsLoss for binary segmentation\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# Training Loop\n",
        "num_epochs = 10\n",
        "# num_epochs = 1\n",
        "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    all_preds = []\n",
        "    all_masks = []\n",
        "\n",
        "    for images, masks in tqdm(train_loader):\n",
        "        images, masks = images.to(device), masks.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = criterion(outputs, masks)\n",
        "\n",
        "        # Calculate additional metrics (if you have a custom dice_loss function)\n",
        "        # dice = dice_loss(masks, outputs)\n",
        "        # total_loss = loss + dice  # Uncomment if using Dice loss\n",
        "        total_loss = loss  # For now, just using BCE loss\n",
        "        epoch_loss += total_loss.item()\n",
        "\n",
        "        # Backpropagation and optimization\n",
        "        optimizer.zero_grad()\n",
        "        total_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Generate predictions\n",
        "        preds = torch.sigmoid(outputs)  # Apply sigmoid since using BCEWithLogitsLoss\n",
        "        preds = (preds > 0.5).float()\n",
        "\n",
        "        # Store predictions and ground truths\n",
        "        all_preds.extend(preds.squeeze(1).cpu().numpy())\n",
        "        all_masks.extend(masks.squeeze(1).cpu().numpy())\n",
        "\n",
        "    # Calculate precision and recall\n",
        "    recall = recall_score_(np.array(all_preds), np.array(all_masks))\n",
        "    precision = precision_score_(np.array(all_preds), np.array(all_masks))\n",
        "    iou = iou_(np.array(all_preds), np.array(all_masks))\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss/len(train_loader)}\")\n",
        "    print(f\"Precision: {recall:.4f}, Recall: {precision:.4f}\")\n",
        "    if recall != 0. and precision != 0.:\n",
        "        print(f'F1 - score : {2/((1/recall) + (1/precision))}')\n",
        "    print(f\"IOU : {iou}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gF2HV-oSknzo"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "epoch_loss = 0\n",
        "all_preds = []\n",
        "all_masks = []\n",
        "\n",
        "for images, masks in tqdm(test_loader):\n",
        "    images, masks = images.to(device), masks.to(device)\n",
        "\n",
        "    # Forward pass\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, masks)  # Cast masks to long if needed\n",
        "    dice = dice_loss(masks, outputs)\n",
        "    total_loss = loss + dice\n",
        "    epoch_loss += total_loss.item()\n",
        "\n",
        "\n",
        "    # Backpropagation and optimization\n",
        "    optimizer.zero_grad()\n",
        "    total_loss.backward()\n",
        "    optimizer.step()\n",
        "    preds = (outputs > 0.5).float()\n",
        "    all_preds.extend(preds.squeeze(1).cpu().numpy())\n",
        "    all_masks.extend(masks.squeeze(1).cpu().numpy())\n",
        "\n",
        "recall = recall_score_(np.array(all_preds), np.array(all_masks))\n",
        "precision = precision_score_(np.array(all_preds), np.array(all_masks))\n",
        "iou = iou_(np.array(all_preds), np.array(all_masks))\n",
        "\n",
        "print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss/len(train_loader)}\")\n",
        "print(f\"Precision: {recall:.4f}, Recall: {precision:.4f}\")\n",
        "if recall != 0. and precision != 0.:\n",
        "    print(f'F1 - score : {2/((1/recall) + (1/precision))}')\n",
        "print(f\"IOU : {iou}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVyN-FG7kp6n"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(np.array(all_preds).flatten(), np.array(all_masks).flatten()))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}